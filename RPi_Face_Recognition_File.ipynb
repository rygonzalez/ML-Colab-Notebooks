{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rygonzalez/ML-Colab-Notebooks/blob/main/RPi_Face_Recognition_File.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbOtePOHNvkP"
      },
      "source": [
        "### CREDITS GO TO ADRIAN ROSEBROCK FOR TUTORIAL CODE IN RPI FACE RECOGNITION SOFTWARE\n",
        "### Tutorial found at: https://www.pyimagesearch.com/2018/06/25/raspberry-pi-face-recognition/\n",
        "\n",
        "# USAGE\n",
        "# python pi_face_recognition.py --cascade haarcascade_frontalface_default.xml --encodings encodings.pickle\n",
        "\n",
        "# import the necessary packages (facial recognition)\n",
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "import face_recognition\n",
        "import argparse\n",
        "import imutils\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "# imports for Arduino-to-RPi communication\n",
        "import serial\n",
        "\n",
        "# instantiate connection to Arduino serial port\n",
        "ser = serial.Serial('/dev/ttyACM0',9600)\n",
        "ser.flush()\n",
        "\n",
        "# construct the argument parser and parse the arguments\n",
        "# forms the \"constructor\" for our python code when we run through command line\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-c\", \"--cascade\", required=True,\n",
        "    help = \"path to where the face cascade resides\")\n",
        "ap.add_argument(\"-e\", \"--encodings\", required=True,\n",
        "    help=\"path to serialized db of facial encodings\")\n",
        "args = vars(ap.parse_args())\n",
        "\n",
        "# load the known faces and embeddings along with OpenCV's Haar\n",
        "# cascade for face detection\n",
        "print(\"[INFO] loading encodings + face detector...\")\n",
        "data = pickle.loads(open(args[\"encodings\"], \"rb\").read())\n",
        "detector = cv2.CascadeClassifier(args[\"cascade\"])\n",
        "\n",
        "# initialize the video stream and allow the camera sensor to warm up\n",
        "print(\"[INFO] starting video stream...\")\n",
        "vs = VideoStream(src=0).start()\n",
        "# vs = VideoStream(usePiCamera=True).start()\n",
        "time.sleep(2.0)\n",
        "\n",
        "# start the FPS counter\n",
        "fps = FPS().start()\n",
        "\n",
        "# loop over frames from the video file stream\n",
        "while True:\n",
        "    # grab the frame from the threaded video stream and resize it\n",
        "    # to 500px (to speedup processing)\n",
        "    frame = vs.read()\n",
        "    frame = imutils.resize(frame, width=500)\n",
        "\n",
        "    # convert the input frame from (1) BGR to grayscale (for face\n",
        "    # detection) and (2) from BGR to RGB (for face recognition)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # detect faces in the grayscale frame\n",
        "    rects = detector.detectMultiScale(gray, scaleFactor=1.1,\n",
        "        minNeighbors=5, minSize=(30, 30),\n",
        "        flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "\n",
        "    # OpenCV returns bounding box coordinates in (x, y, w, h) order\n",
        "    # but we need them in (top, right, bottom, left) order, so we\n",
        "    # need to do a bit of reordering\n",
        "    boxes = [(y, x + w, y + h, x) for (x, y, w, h) in rects]\n",
        "\n",
        "    # compute the facial embeddings for each face bounding box\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "    names = []\n",
        "\n",
        "    # loop over the facial embeddings\n",
        "    for encoding in encodings:\n",
        "        # attempt to match each face in the input image to our known\n",
        "        # encodings\n",
        "        matches = face_recognition.compare_faces(data[\"encodings\"],\n",
        "            encoding)\n",
        "        name = \"Unknown\"\n",
        "\n",
        "        ### THIS IS WHERE WE SEND TO THE ARDUINO###\n",
        "\n",
        "        # check to see if we have found a match\n",
        "        if True in matches:\n",
        "            # find the indexes of all matched faces then initialize a\n",
        "            # dictionary to count the total number of times each face\n",
        "            # was matched\n",
        "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
        "            counts = {}\n",
        "\n",
        "            # loop over the matched indexes and maintain a count for\n",
        "            # each recognized face face\n",
        "            for i in matchedIdxs:\n",
        "                name = data[\"names\"][i]\n",
        "                counts[name] = counts.get(name, 0) + 1\n",
        "\n",
        "            # determine the recognized face with the largest number\n",
        "            # of votes (note: in the event of an unlikely tie Python\n",
        "            # will select first entry in the dictionary)\n",
        "            name = max(counts, key=counts.get)\n",
        "\n",
        "        # update the list of names\n",
        "        names.append(name)\n",
        "\n",
        "        # Sends '555' as a string converted to byted when Raspberry Pi\n",
        "        # detects a face.\n",
        "        if True in matches:\n",
        "              ser.write(str(\"555\\n\").encode())\n",
        "\n",
        "    # loop over the recognized faces\n",
        "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
        "        # draw the predicted face name on the image\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom),\n",
        "            (0, 255, 0), 2)\n",
        "        y = top - 15 if top - 15 > 15 else top + 15\n",
        "        cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            0.75, (0, 255, 0), 2)\n",
        "\n",
        "    # display the image to our screen\n",
        "    cv2.imshow(\"Frame\", frame)\n",
        "    key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "    # if the `q` key was pressed, break from the loop\n",
        "    if key == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "    # update the FPS counter\n",
        "    fps.update()\n",
        "\n",
        "# stop the timer and display FPS information\n",
        "fps.stop()\n",
        "print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
        "print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
        "\n",
        "# do a bit of cleanup\n",
        "cv2.destroyAllWindows()\n",
        "vs.stop()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}